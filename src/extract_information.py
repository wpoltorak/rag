import os
import gradio as gr
from gradio.themes.base import Base
from pymongo import MongoClient
from langchain_openai import OpenAIEmbeddings
from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_openai import OpenAI

# from langchain.chains import RetrievalQA
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

from langchain_core.prompts import ChatPromptTemplate

from dotenv import load_dotenv

load_dotenv()

client = MongoClient(os.environ.get("mongodb.connect_string"))
dbName = "langchain_demo"
collectionName = "collection_of_text_blobs"
collection = client[dbName][collectionName]

embeddings = OpenAIEmbeddings(openai_api_key=os.environ.get("openai.api_key"))
vectoreStore = MongoDBAtlasVectorSearch(collection, embeddings)


def query_data(query):
    docs = vectoreStore.similarity_search(query, k=1)
    as_output = docs[0].page_content

    llm = OpenAI(openai_api_key=os.environ.get("openai.api_key"), temperature=0)
    retriever = vectoreStore.as_retriever
    system_prompt = (
        "Use the given context to answer the question. "
        "If you don't know the answer, say you don't know. "
        "Use three sentence maximum and keep the answer concise."
        "\n\n{context}"
    )
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("human", "{input}"),
        ]
    )
    # from langchain.chains import create_retrieval_chain
    # qa = RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)
    question_answer_chain = create_stuff_documents_chain(llm, prompt).with_config()
    qa = create_retrieval_chain(retriever, question_answer_chain)
    # retriever_output = qa.run(query)
    retriever_output = qa.invoke({"input": query})
    return as_output, retriever_output


with gr.Blocks(
    theme=Base(), title="Question Anserwing App using Vector Search + RAG"
) as demo:
    gr.Markdown(
        """
                # Qestion Answering App using Atlas Vector Search + RAG Architecture
                """
    )
    textbox = gr.Textbox(label="Enter your question:")
    with gr.Row():
        button = gr.Button("Submit", variant="primary")
    with gr.Column():
        output1 = gr.Textbox(
            lines=1,
            max_lines=10,
            label="Output with just Atlas Vector Search (returns text field as is):",
        )
        output2 = gr.Textbox(
            lines=1,
            max_lines=10,
            label="Output generated by chaining Atlas Vector Search to Langchain's RetrievalQA + OpenAI LLM:",
        )
    button.click(query_data, textbox, outputs=[output1, output2])
demo.launch()
